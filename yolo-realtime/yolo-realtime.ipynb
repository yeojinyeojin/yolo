{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "# from util import * "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "LABELSPATH = '../../darknet/data/coco.names'\n",
    "CONFIGPATH = '../../darknet/cfg/yolov3.cfg'\n",
    "WEIGHTSPATH = '../yolov3.weights'\n",
    "\n",
    "CONFIDENCE_THS = 0.5\n",
    "NMS_THS = 0.3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "LABELS = open(LABELSPATH).read().strip().split(\"\\n\")\n",
    "\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0,255,size=(len(LABELS),3),dtype=\"uint8\")\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(CONFIGPATH,WEIGHTSPATH)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def test_on_image(net,imgfile):\n",
    "    image = cv2.imread(imgfile)\n",
    "    (H,W) = image.shape[:2]\n",
    "\n",
    "    output_ln = net.getLayerNames()\n",
    "    output_ln = [output_ln[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image,1/255.0,(416,416),swapRB=True,crop=False)\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    layer_outputs = net.forward(output_ln)\n",
    "    end = time.time()\n",
    "\n",
    "    print('[INFO] YOLO took {:.6f} secs'.format(end-start))\n",
    "\n",
    "    return image,layer_outputs,H,W"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def process_outputs(layer_outputs,H,W):\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            if confidence > CONFIDENCE_THS:\n",
    "                box = detection[0:4] * np.array([W,H,W,H])\n",
    "                (center_x,center_y,width,height) = box.astype(\"int\")\n",
    "\n",
    "                x = int(center_x - (width/2))\n",
    "                y = int(center_y - (height/2))\n",
    "\n",
    "                boxes.append([x,y,int(width),int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes,confidences,CONFIDENCE_THS,NMS_THS)\n",
    "    return idxs,boxes,confidences,classIDs\n",
    "\n",
    "def draw_outputs(idxs,boxes,confidences,classIDs,image):\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            (x,y) = (boxes[i][0],boxes[i][1])\n",
    "            (w,h) = (boxes[i][2],boxes[i][3])\n",
    "\n",
    "            color = [int(c) for c in COLORS[classIDs[i]]]\n",
    "            cv2.rectangle(image,(x,y),(x+w,y+h),color,2)\n",
    "            text = \"{}:{:.4f}\".format(LABELS[classIDs[i]],confidences[i])\n",
    "            cv2.putText(image,text,(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,2)\n",
    "    \n",
    "    return image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "imagefile = '../images/dog-cycle-car.png'\n",
    "image,layer_outputs,H,W = test_on_image(net,imagefile)\n",
    "idxs,boxes,confidences,classIDs = process_outputs(layer_outputs,H,W)\n",
    "output_image = draw_outputs(idxs,boxes,confidences,classIDs,image)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] YOLO took 0.441732 secs\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "cv2.imshow(\"\",output_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('yoloing': conda)"
  },
  "interpreter": {
   "hash": "8816270150bc4a5ff6b744185fa9ee8005e66bbce302098329e884586c1533d5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}